{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea501abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dropout, BatchNormalization\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88556a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset directories for training, test, and validation dataset\n",
    "train_dir = './dataset_wildfire/train'\n",
    "test_dir = './dataset_wildfire/test'\n",
    "valid_dir = './dataset_wildfire/valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d70e5126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each image is 350x350px\n",
    "img_size = (350, 350)\n",
    "# Each epoch will be trained in 32 batches of images\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ec99c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code in this section is inspired by:\n",
    "# https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
    "\n",
    "\n",
    "# Using ImageDataGenerator to create more variety of images in the dataset, since satellite images of forests mostly look static by nature\n",
    "train_datagen = ImageDataGenerator(\n",
    "    # Normalize image\n",
    "    rescale=1./255,\n",
    "    # Add random shearing to the image \n",
    "    shear_range=0.2,\n",
    "    # Add random zooming to the image\n",
    "    zoom_range=0.2,\n",
    "    # Randomly flip images\n",
    "    horizontal_flip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07cf33cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize images in both test and validation images\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eed24fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30250 images belonging to 2 classes.\n",
      "Found 6300 images belonging to 2 classes.\n",
      "Found 6300 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Code in this section is inspired by:\n",
    "# https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
    "\n",
    "\n",
    "# The train, test, and valid datasets are organized into \"wildfire\" and \"nowildfire\" sub-folders. We made use of the \n",
    "# flow_from_directory function, and set the class_mode to binary appropriately for the function to \n",
    "# automatically load and label the images.\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    # set shuffle to true for training only to add more \"randomness\" during each epoch\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    valid_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=False  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03c7c66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customized LeNet model we designed as described in the paper.\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(16, (5, 5), activation='relu', input_shape=(350, 350, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(layers.Conv2D(32, (5, 5), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d698c1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify to use binary crossentropy to measure the loss, and adam optimizer to update the weights\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e85d0934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "945/945 [==============================] - 381s 398ms/step - loss: 0.2364 - accuracy: 0.9097\n",
      "Epoch 2/10\n",
      "945/945 [==============================] - 352s 372ms/step - loss: 0.1857 - accuracy: 0.9259\n",
      "Epoch 3/10\n",
      "945/945 [==============================] - 363s 385ms/step - loss: 0.1626 - accuracy: 0.9368\n",
      "Epoch 4/10\n",
      "945/945 [==============================] - 361s 382ms/step - loss: 0.1471 - accuracy: 0.9423\n",
      "Epoch 5/10\n",
      "945/945 [==============================] - 365s 386ms/step - loss: 0.1399 - accuracy: 0.9461\n",
      "Epoch 6/10\n",
      "945/945 [==============================] - 361s 382ms/step - loss: 0.1287 - accuracy: 0.9524\n",
      "Epoch 7/10\n",
      "945/945 [==============================] - 351s 371ms/step - loss: 0.1219 - accuracy: 0.9537\n",
      "Epoch 8/10\n",
      "945/945 [==============================] - 368s 389ms/step - loss: 0.1124 - accuracy: 0.9560\n",
      "Epoch 9/10\n",
      "945/945 [==============================] - 364s 385ms/step - loss: 0.1062 - accuracy: 0.9603\n",
      "Epoch 10/10\n",
      "945/945 [==============================] - 355s 376ms/step - loss: 0.1016 - accuracy: 0.9615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15a3e7df460>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "# \"train_generator\" returns an image from the training dataset and modified with \n",
    "# shearing, zooming, and rotating as described in ln[4]\n",
    "\n",
    "# Number of epochs is 10.\n",
    "\n",
    "# Number of batches in each epoch is defined to be train_generator.samples / batch_size = 945 batches, to ensure\n",
    "# a complete pass of the entire dataset in every epoch.\n",
    "model.fit(train_generator, epochs=10, steps_per_epoch=train_generator.samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffa0a5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/DAKU/Desktop/Wildfire Model/final_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/DAKU/Desktop/Wildfire Model/final_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('./final_model', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e7975d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197/197 [==============================] - 13s 65ms/step - loss: 0.2129 - accuracy: 0.9381\n",
      "Validation Loss: 0.21291281282901764\n",
      "Validation Accuracy: 93.81%\n"
     ]
    }
   ],
   "source": [
    "validation_result = model.evaluate(valid_generator)\n",
    "print(f'Validation Loss: {validation_result[0]}')\n",
    "print(f'Validation Accuracy: {validation_result[1] * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26145d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 13s 64ms/step - loss: 0.2300 - accuracy: 0.9434\n",
      "Test Accuracy: 94.34%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.samples // batch_size)\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
